{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "def build_artificial_dataset(num_samples: int):\n",
    "    data = []\n",
    "    sampling_rates = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        y, sr = librosa.load(librosa.ex('nutcracker'))\n",
    "        data.append(y)\n",
    "        sampling_rates.append(sr)\n",
    "    features_dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "    labels_dataset = tf.data.Dataset.from_tensor_slices(sampling_rates)\n",
    "    dataset = tf.data.Dataset.zip((features_dataset, labels_dataset))\n",
    "\n",
    "    return dataset\n",
    "\n",
    "ds = build_artificial_dataset(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiomentations import Compose, AddGaussianNoise, PitchShift, Shift\n",
    "\n",
    "augmentations_pipeline = Compose(\n",
    "    [\n",
    "        AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "        PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
    "        Shift(min_fraction=-0.5, max_fraction=0.5, p=0.5),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pipeline(y, sr):\n",
    "    shifted = augmentations_pipeline(y, sr)\n",
    "    return shifted\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def tf_apply_pipeline(feature, sr, ):\n",
    "    \"\"\"\n",
    "    Applies the augmentation pipeline to audio files\n",
    "    @param y: audio data\n",
    "    @param sr: sampling rate\n",
    "    @return: augmented audio data\n",
    "    \"\"\"\n",
    "    augmented_feature = tf.numpy_function(\n",
    "        apply_pipeline, inp=[feature, sr], Tout=tf.float32, name=\"apply_pipeline\"\n",
    "    )\n",
    "\n",
    "    return augmented_feature, sr\n",
    "\n",
    "\n",
    "def augment_audio_dataset(dataset: tf.data.Dataset):\n",
    "    dataset = dataset.map(tf_apply_pipeline)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = augment_audio_dataset(ds)\n",
    "ds = ds.map(lambda y, sr: (tf.expand_dims(y, axis=-1), sr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio_data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1885ad2173303a0507687c55f9d9c4301259c04b4cc12922c1715ca1b949c892"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
